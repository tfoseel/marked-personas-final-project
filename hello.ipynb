{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marked_words import marked_words\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "import sklearn.feature_selection\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(dic):\n",
    "    full_list = []\n",
    "    for word in sorted(dic,key=lambda x: x[1],reverse=True):\n",
    "        # print(\"%s, %.2f\" % (word[0],word[1]))\n",
    "        full_list.append(word[0])\n",
    "    return full_list\n",
    "\n",
    "def anonymize(bio, replacement=\"\"):\n",
    "    \"\"\"\n",
    "    지역 및 성별을 직접적으로 나타내는 단어를 masking하는 함수\n",
    "    \"\"\"\n",
    "    bio = re.sub(r\"남|여|녀|남자|여자|남성|여성|남편|부인|그|그녀\", replacement, bio)\n",
    "    bio = re.sub(r\"서울|전라도|경상도|제주도|전라|경상|제주\", replacement, bio)\n",
    "    return bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/gpt3_generations.csv')\n",
    "\n",
    "gpt3_mw = {}\n",
    "\n",
    "# 서울을 majority로 보았을 때, 다른 지역의 marked words\n",
    "for province in df['province'].unique():\n",
    "    # print('\\n Top words for %s \\n-------' % province)\n",
    "    outs = pprint(marked_words(df, [province], ['province'], ['서울']))\n",
    "    gpt3_mw[province] = outs\n",
    "\n",
    "# 다른 지역을 각각 majority로 보았을 때, 서울의 marked words\n",
    "temps = []\n",
    "for province in df[\"province\"].unique():\n",
    "    # print('\\n Top words for %s \\n-------' % province)\n",
    "    temp = pprint(marked_words(df, [\"서울\"], [\"province\"], [province]))\n",
    "    temps.extend(temp)\n",
    "seen = Counter(temps).most_common()\n",
    "gpt3_mw[\"서울\"] = [w for w, c in seen if c == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남자를 majority로 보았을 때, 여자의 marked words\n",
    "for gender in df[\"gender\"].unique():\n",
    "    # print('\\n Top words for %s \\n-------' % gender)\n",
    "    outs = pprint(marked_words(df, [gender], [\"gender\"], [\"남자\"]))\n",
    "    gpt3_mw[gender] = outs\n",
    "\n",
    "# 여자를 majority로 보았을 때, 남자의 marked words\n",
    "temps = []\n",
    "for gender in df[\"gender\"].unique():\n",
    "    # print('\\n Top words for %s \\n-------' % gender)\n",
    "    temp = pprint(marked_words(df, [\"남자\"], [\"gender\"], [gender]))\n",
    "    temps.extend(temp)\n",
    "seen = Counter(temps).most_common()\n",
    "gpt3_mw[\"남자\"] = [w for w, c in seen if c == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울 남자를 majority로 보았을 때, 다른 intersectional 집단의 marked words\n",
    "for province in df[\"province\"].unique():\n",
    "    for gen in df[\"gender\"].unique():\n",
    "        gpt3_mw[f\"{province} {gen}\"] = pprint(\n",
    "            marked_words(df, [province, gen], [\"province\", \"gender\"], [\"서울\", \"남자\"])\n",
    "        )\n",
    "\n",
    "# 다른 intersectional 집단을 majority로 보았을 때, 서울 남자의 marked words\n",
    "temps = []\n",
    "for province in df[\"province\"].unique():\n",
    "    for gender in df[\"gender\"].unique():\n",
    "        # print('\\n Top words for %s \\n-------' % gender)\n",
    "        temp = pprint(marked_words(df, [\"서울\", \"남자\"], [\"province\", \"gender\"], [province, gender]))\n",
    "        temps.extend(temp)\n",
    "seen = Counter(temps).most_common()\n",
    "gpt3_mw[\"서울 남자\"] = [w for w, c in seen if c == 4 * 2 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울의 marked word 개수 : 26\n",
      "제주도의 marked word 개수 : 35\n",
      "경상도의 marked word 개수 : 27\n",
      "전라도의 marked word 개수 : 18\n",
      "여자의 marked word 개수 : 26\n",
      "남자의 marked word 개수 : 24\n",
      "서울 여자의 marked word 개수 : 0\n",
      "서울 남자의 marked word 개수 : 0\n",
      "제주도 여자의 marked word 개수 : 18\n",
      "제주도 남자의 marked word 개수 : 6\n",
      "경상도 여자의 marked word 개수 : 8\n",
      "경상도 남자의 marked word 개수 : 1\n",
      "전라도 여자의 marked word 개수 : 5\n",
      "전라도 남자의 marked word 개수 : 2\n"
     ]
    }
   ],
   "source": [
    "for key in gpt3_mw.keys():\n",
    "    print(f\"{key}의 marked word 개수 : {len(gpt3_mw[key])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROVINCE\n",
      "Mean accuracy across province groups: 0.90 ± 0.05\n",
      "GENDER\n",
      "Mean accuracy across gender groups: 0.70 ± 0.00\n",
      "PROVINCEGENDER\n",
      "Mean accuracy across provincegender groups: 0.90 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "# SVM으로 직접적으로 집단에 대한 정보를 제공하는 단어를 masking한 뒤, 각 집단을 분류하는 성능을 측정\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, decode_error=\"ignore\")\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "\n",
    "def anonymize(bio, replacement=\"\"):\n",
    "    \"\"\"\n",
    "    지역 및 성별을 직접적으로 나타내는 단어를 masking하는 함수\n",
    "    \"\"\"\n",
    "    bio = re.sub(r\"남|여|녀|남자|여자|남편|부인|아내|그|그녀\", replacement, bio)\n",
    "    bio = re.sub(r\"서울|전라도|경상도|제주도|전라|경상|제주\", replacement, bio)\n",
    "    return bio\n",
    "\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy[\"provincegender\"] = df_copy[\"province\"] + df_copy[\"gender\"]\n",
    "data = (\n",
    "    df_copy[\"text\"]\n",
    "    .apply(lambda s: \" \".join(mecab.morphs(s)))\n",
    "    .str.lower()\n",
    "    .replace(\"[^\\w\\s]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "top_words = dict()\n",
    "dv3_svm = {}\n",
    "for st in [\"province\", \"gender\", \"provincegender\"]:\n",
    "    print(st.upper())\n",
    "    concept_data = [anonymize(d) for d in data]\n",
    "    labels = df_copy[st]\n",
    "    bios_data_train, bios_data_test, Y_train, Y_test = train_test_split(\n",
    "        concept_data, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    vectorizer = CountVectorizer(analyzer=\"word\", min_df=0.001, binary=False)\n",
    "    X_train = vectorizer.fit_transform(bios_data_train)\n",
    "    X_test = vectorizer.transform(bios_data_test)\n",
    "    accs = []\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for r in df_copy[st].unique():\n",
    "        svm = SVC(kernel=\"linear\")\n",
    "        Y_train_bin = Y_train == r\n",
    "        svm.fit(X_train, Y_train_bin)\n",
    "        acc = sklearn.metrics.accuracy_score(Y_test == r, svm.predict(X_test))\n",
    "        # print(\"%s Accuracy: %.2f\"%(r, acc))\n",
    "        accs.append(acc)\n",
    "        coef = svm.coef_.toarray()[0]\n",
    "        _, names = zip(*sorted(zip(coef, feature_names)))\n",
    "        # print(\"Top 10 words: %s\" % str(names[-10:][::-1]))\n",
    "        dv3_svm[r] = names[-10:][::-1]\n",
    "    print(\n",
    "        \"Mean accuracy across %s groups: %.2f ± %.2f\"\n",
    "        % (st, np.mean(accs), np.std(accs))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
